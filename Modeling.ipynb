{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f2f4b7-6c06-42bc-8793-dc53b6e96772",
   "metadata": {},
   "source": [
    "#### Persiapan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522808e4-b09c-41a5-ac95-bc2539ea7fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'heart_statlog_cleveland_hungary_final_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheart_statlog_cleveland_hungary_final_cleaned.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m display(df)\n\u001b[0;32m     14\u001b[0m X_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\Week_1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\Week_1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\Week_1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\Week_1\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\anaconda3\\envs\\Week_1\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'heart_statlog_cleveland_hungary_final_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('heart_statlog_cleveland_hungary_final_cleaned.csv')\n",
    "display(df)\n",
    "X_data = df.copy().drop(columns=['target'])\n",
    "y_data = df.copy()['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fff43c-65d1-4043-905b-1d20298fd1fb",
   "metadata": {},
   "source": [
    "#### Model Logistic Regression\n",
    "Alasan Utama: Sederhana, cepat, dan efektif untuk klasifikasi biner.\n",
    "\n",
    "Penjelasan: Logistic Regression adalah model yang sangat umum untuk masalah klasifikasi biner, seperti memprediksi apakah seseorang memiliki penyakit jantung (target = 1) atau tidak (target = 0). Karena data yang Anda miliki mungkin tidak terlalu kompleks atau sangat besar, Logistic Regression dapat memberi hasil yang cukup baik dalam waktu yang singkat.\n",
    "\n",
    "Kenapa Memilih Ini: Ini adalah model baseline yang cepat untuk melihat seberapa baik data bisa diprediksi dengan model sederhana. Selain itu, model ini memberikan interpretabilitas yang tinggi, yang berarti kita bisa mengetahui faktor-faktor yang mempengaruhi keputusan model (misalnya, apakah usia atau tekanan darah mempengaruhi risiko penyakit jantung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1745a697-7c6e-4a7f-9da3-eab3ddc30a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "X = X_data.copy().to_numpy()\n",
    "y = y_data.copy().to_numpy()\n",
    "\n",
    "\n",
    "# Function untuk membuat pipeline model: Pipeline menyusun preprocessing (StandardScaler) dan model LogisticRegression jadi satu.\n",
    "def create_pipeline(C=1.0):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', LogisticRegression(C=C, max_iter=1000, solver='liblinear'))\n",
    "    ])\n",
    "# C: regularisasi (semakin kecil = regulasi makin kuat).\n",
    "# Solver liblinear cocok untuk dataset kecil.\n",
    "\n",
    "param_dist = {\n",
    "    'clf__C': loguniform(0.001, 100),\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['saga'],\n",
    "    # 'clf__l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'clf__max_iter': randint(2000, 5000)\n",
    "}\n",
    "\n",
    "# Hyperparameter settings\n",
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['saga'],\n",
    "    # 'clf__l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'clf__max_iter': [5000, 10000]\n",
    "}\n",
    "\n",
    "# Confusion matrix memberikan visualisasi tentang performa model dalam memprediksi kelas positif dan negatif, serta berapa banyak kesalahan yang terjadi (false positives dan false negatives).\n",
    "def plot_multiple_confusion_matrices(conf_matrices, title):\n",
    "    n = len(conf_matrices)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(3.5 * n, 3.5))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (cm, name) in enumerate(conf_matrices):\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=axes[i], cmap='Blues', colorbar=False)\n",
    "        axes[i].set_title(name)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Pastikan hanya panggil show sekali di sini\n",
    "    plt.close(fig)  # ⬅⬅⬅ Tambahkan ini untuk menghindari dobel\n",
    "    \n",
    "# Fungsi evaluasi untuk KFold dan StratifiedKFold\n",
    "def evaluate_with_cv(cv_method, use_grid=False, use_random=False, show_conf_matrix=False):\n",
    "    default_scores = []\n",
    "    grid_scores = []\n",
    "    random_scores = []\n",
    "    fold_num = 1\n",
    "\n",
    "    # Untuk menyimpan semua confusion matrices\n",
    "    conf_matrices_default = []\n",
    "    conf_matrices_grid = []\n",
    "    conf_matrices_random = []\n",
    "\n",
    "    for train_idx, test_idx in cv_method.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Default\n",
    "        model = create_pipeline()\n",
    "        model.fit(X_train, y_train)\n",
    "        default_scores.append(model.score(X_test, y_test))\n",
    "\n",
    "        if show_conf_matrix:\n",
    "            y_pred = model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            conf_matrices_default.append((cm, f\"Default-Fold {fold_num}\"))\n",
    "\n",
    "        # GridSearchCV: melakukan pencarian yang lebih ekstensif dengan mencoba semua kombinasi parameter yang ditentukan dalam param_grid.\n",
    "        if use_grid:\n",
    "            grid = GridSearchCV(create_pipeline(), param_grid, cv=3)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_scores.append(grid.best_estimator_.score(X_test, y_test))\n",
    "            \n",
    "            if show_conf_matrix:\n",
    "                y_pred = grid.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_grid.append((cm, f\"GridSearch-Fold {fold_num}\"))\n",
    "\n",
    "        # RandomizedSearchCV: memilih kombinasi parameter secara acak dari distribusi yang diberikan dalam param_dist, dengan tujuan mempercepat pencarian.\n",
    "        if use_random:\n",
    "            rand = RandomizedSearchCV(create_pipeline(), param_distributions=param_dist, n_iter=10, cv=3, random_state=42)\n",
    "            rand.fit(X_train, y_train)\n",
    "            random_scores.append(rand.best_estimator_.score(X_test, y_test))\n",
    "            \n",
    "            if show_conf_matrix:\n",
    "                y_pred = rand.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_random.append((cm, f\"RandomizedSearch-Fold {fold_num}\"))\n",
    "\n",
    "        fold_num += 1\n",
    "\n",
    "    # Tampilkan semua confusion matrix setelah loop\n",
    "    if show_conf_matrix:\n",
    "        plot_multiple_confusion_matrices(conf_matrices_default, \"Confusion Matrix - Default\")\n",
    "        if use_grid:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_grid, \"Confusion Matrix - GridSearchCV\")\n",
    "        if use_random:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_random, \"Confusion Matrix - RandomizedSearchCV\")\n",
    "\n",
    "    return default_scores, grid_scores, random_scores\n",
    "\n",
    "\n",
    "# Fungsi plotting hasil\n",
    "def plot_fold_results(fold_scores_dict, title):\n",
    "    folds = [f'Fold {i+1}' for i in range(len(next(iter(fold_scores_dict.values()))))]\n",
    "    y_pos = np.arange(len(folds))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    bar_height = 0.2\n",
    "    offsets = [-bar_height, 0, bar_height]\n",
    "    colors = ['gray', 'skyblue', 'lightgreen']\n",
    "    labels = ['Default', 'GridSearchCV', 'RandomizedSearchCV']\n",
    "\n",
    "    for i, (label, scores) in enumerate(fold_scores_dict.items()):\n",
    "        plt.barh(y_pos + offsets[i], scores, height=bar_height, color=colors[i], label=labels[i])\n",
    "        for j, score in enumerate(scores):\n",
    "            plt.text(score + 0.002, y_pos[j] + offsets[i], f\"{score:.4f}\", va='center', ha='left')\n",
    "\n",
    "    # Hitung mean dari masing-masing\n",
    "    mean_default = np.mean(kfold_default)\n",
    "    mean_grid = np.mean(kfold_grid)\n",
    "    mean_random = np.mean(kfold_random)\n",
    "    \n",
    "    # Tambahkan titik/marker sebagai legend dan penanda mean\n",
    "    plt.scatter([mean_default]*len(kfold_default), range(len(kfold_default)),\n",
    "                marker='o', color='blue', label='Mean (Default)', zorder=5)\n",
    "    \n",
    "    plt.scatter([mean_grid]*len(kfold_grid), range(len(kfold_grid)),\n",
    "                marker='x', color='navy', label='Mean (GridSearch)', zorder=5)\n",
    "    \n",
    "    plt.scatter([mean_random]*len(kfold_random), range(len(kfold_random)),\n",
    "                marker='D', color='green', label='Mean (RandomSearch)', zorder=5)\n",
    "    plt.xlim(0.75, 1.0)\n",
    "\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Folds')\n",
    "    plt.yticks(y_pos, folds)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluasi untuk KFold dan StratifiedKFold\n",
    "\n",
    "# KFold membagi data menjadi K bagian yang tidak tumpang tindih, dan model dilatih dan diuji pada setiap bagian.\n",
    "# StratifiedKFold memastikan bahwa distribusi target (positif/negatif) tetap seimbang pada setiap bagian.\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "plot_fold_results({\n",
    "    'Default': kfold_default,\n",
    "    'GridSearchCV': kfold_grid,\n",
    "    'RandomizedSearchCV': kfold_random\n",
    "}, 'KFold Cross-Validation Results')\n",
    "kfold_default, kfold_grid, kfold_random = evaluate_with_cv(kfold, use_grid=True, use_random=True, show_conf_matrix=True)\n",
    "\n",
    "plot_fold_results({\n",
    "    'Default': strat_default,\n",
    "    'GridSearchCV': strat_grid,\n",
    "    'RandomizedSearchCV': strat_random\n",
    "}, 'StratifiedKFold Cross-Validation Results')\n",
    "strat_default, strat_grid, strat_random = evaluate_with_cv(strat_kfold, use_grid=True, use_random=True, show_conf_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eff21e-3a0f-454d-aefb-cece9d12f848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import loguniform, randint\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load dataset\n",
    "X = X_data.copy().to_numpy()\n",
    "y = y_data.copy().to_numpy()\n",
    "\n",
    "# Pipeline builder\n",
    "def create_pipeline(C=1.0):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA(n_components=2)),\n",
    "        ('clf', LogisticRegression(C=C, max_iter=1000, solver='liblinear'))\n",
    "    ])\n",
    "\n",
    "# Visualisasi awal PCA\n",
    "def run_pipeline_with_visualization(X, y, pipeline_fn=create_pipeline, test_size=0.2, random_state=42, **pipeline_kwargs):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    pipeline = pipeline_fn(**pipeline_kwargs)\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    X_pca_all = pipeline.named_steps['pca'].transform(\n",
    "        pipeline.named_steps['scaler'].transform(X)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(\"Visualisasi PCA 2D - Sebelum Evaluasi\")\n",
    "    plt.scatter(X_pca_all[y == 0, 0], X_pca_all[y == 0, 1], c='blue', label='Class 0')\n",
    "    plt.scatter(X_pca_all[y == 1, 0], X_pca_all[y == 1, 1], c='red', label='Class 1')\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "# Visualisasi PCA berdasarkan prediksi model\n",
    "def plot_pca_predictions(pipeline, X, y_true, title=\"PCA Scatter with Predictions\"):\n",
    "    X_scaled = pipeline.named_steps['scaler'].transform(X)\n",
    "    X_pca = pipeline.named_steps['pca'].transform(X_scaled)\n",
    "    y_pred = pipeline.predict(X)\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.title(title)\n",
    "\n",
    "    correct = y_pred == y_true\n",
    "    incorrect = ~correct\n",
    "\n",
    "    plt.scatter(X_pca[correct, 0], X_pca[correct, 1], c='green', label='Benar', alpha=0.6)\n",
    "    plt.scatter(X_pca[incorrect, 0], X_pca[incorrect, 1], c='red', label='Salah', marker='x', alpha=0.6)\n",
    "\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Param search space\n",
    "param_dist = {\n",
    "    'clf__C': loguniform(0.001, 100),\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['saga'],\n",
    "    'clf__max_iter': randint(2000, 5000)\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__solver': ['saga'],\n",
    "    'clf__max_iter': [5000, 10000]\n",
    "}\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_multiple_confusion_matrices(conf_matrices, title):\n",
    "    n = len(conf_matrices)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(3.5 * n, 3.5))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (cm, name) in enumerate(conf_matrices):\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=axes[i], cmap='Blues', colorbar=False)\n",
    "        axes[i].set_title(name)\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "# Evaluasi dengan cross-validation\n",
    "def evaluate_with_cv(cv_method, use_grid=False, use_random=False, show_conf_matrix=False):\n",
    "    default_scores, grid_scores, random_scores = [], [], []\n",
    "    conf_matrices_default, conf_matrices_grid, conf_matrices_random = [], [], []\n",
    "    fold_num = 1\n",
    "\n",
    "    for train_idx, test_idx in cv_method.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Default\n",
    "        model = create_pipeline()\n",
    "        model.fit(X_train, y_train)\n",
    "        default_scores.append(model.score(X_test, y_test))\n",
    "\n",
    "        if show_conf_matrix:\n",
    "            y_pred = model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            conf_matrices_default.append((cm, f\"Default-Fold {fold_num}\"))\n",
    "\n",
    "        # GridSearch\n",
    "        if use_grid:\n",
    "            grid = GridSearchCV(create_pipeline(), param_grid, cv=3)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_scores.append(grid.best_estimator_.score(X_test, y_test))\n",
    "\n",
    "            if show_conf_matrix:\n",
    "                y_pred = grid.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_grid.append((cm, f\"GridSearch-Fold {fold_num}\"))\n",
    "\n",
    "        # RandomizedSearch\n",
    "        if use_random:\n",
    "            rand = RandomizedSearchCV(create_pipeline(), param_distributions=param_dist, n_iter=10, cv=3, random_state=42)\n",
    "            rand.fit(X_train, y_train)\n",
    "            random_scores.append(rand.best_estimator_.score(X_test, y_test))\n",
    "\n",
    "            if show_conf_matrix:\n",
    "                y_pred = rand.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_random.append((cm, f\"RandomSearch-Fold {fold_num}\"))\n",
    "\n",
    "        fold_num += 1\n",
    "\n",
    "    # Plot semua confusion matrix\n",
    "    if show_conf_matrix:\n",
    "        plot_multiple_confusion_matrices(conf_matrices_default, \"Confusion Matrix - Default\")\n",
    "        if use_grid:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_grid, \"Confusion Matrix - GridSearchCV\")\n",
    "        if use_random:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_random, \"Confusion Matrix - RandomizedSearchCV\")\n",
    "\n",
    "    return default_scores, grid_scores, random_scores\n",
    "\n",
    "# Plot hasil cross-validation\n",
    "def plot_fold_results(fold_scores_dict, title):\n",
    "    folds = [f'Fold {i+1}' for i in range(len(next(iter(fold_scores_dict.values()))))]\n",
    "    y_pos = np.arange(len(folds))\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    bar_height = 0.2\n",
    "    offsets = [-bar_height, 0, bar_height]\n",
    "    colors = ['gray', 'skyblue', 'lightgreen']\n",
    "    labels = list(fold_scores_dict.keys())\n",
    "\n",
    "    for i, (label, scores) in enumerate(fold_scores_dict.items()):\n",
    "        plt.barh(y_pos + offsets[i], scores, height=bar_height, color=colors[i], label=label)\n",
    "        for j, score in enumerate(scores):\n",
    "            plt.text(score + 0.002, y_pos[j] + offsets[i], f\"{score:.4f}\", va='center', ha='left')\n",
    "\n",
    "    # Plot rata-rata\n",
    "    for i, (label, scores) in enumerate(fold_scores_dict.items()):\n",
    "        mean_score = np.mean(scores)\n",
    "        plt.scatter([mean_score]*len(scores), y_pos + offsets[i], marker='D', s=50, label=f'Mean ({label})')\n",
    "    \n",
    "\n",
    "    plt.xlim(0.75, 1.0)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Folds')\n",
    "    plt.yticks(y_pos, folds)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main function untuk jalankan semua langkah\n",
    "def run_all(X, y):\n",
    "    print(\">> Visualisasi PCA\")\n",
    "    run_pipeline_with_visualization(X, y, pipeline_fn=create_pipeline, C=1.0)\n",
    "\n",
    "    print(\">> Evaluasi KFold\")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    kfold_default, kfold_grid, kfold_random = evaluate_with_cv(\n",
    "        kfold, use_grid=True, use_random=True, show_conf_matrix=True\n",
    "    )\n",
    "    plot_fold_results({\n",
    "        'Default': kfold_default,\n",
    "        'GridSearchCV': kfold_grid,\n",
    "        'RandomizedSearchCV': kfold_random\n",
    "    }, 'KFold Cross-Validation Results')\n",
    "\n",
    "    print(\">> Evaluasi StratifiedKFold\")\n",
    "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    strat_default, strat_grid, strat_random = evaluate_with_cv(\n",
    "        strat_kfold, use_grid=True, use_random=True, show_conf_matrix=True\n",
    "    )\n",
    "    plot_fold_results({\n",
    "        'Default': strat_default,\n",
    "        'GridSearchCV': strat_grid,\n",
    "        'RandomizedSearchCV': strat_random\n",
    "    }, 'StratifiedKFold Cross-Validation Results')\n",
    "\n",
    "    print(\">> Visualisasi Hasil Prediksi di PCA 2D\")\n",
    "    pipeline = create_pipeline(C=1.0)\n",
    "    pipeline.fit(X, y)\n",
    "    plot_pca_predictions(pipeline, X, y, title=\"PCA Scatter Based on Predictions\")\n",
    "\n",
    "\n",
    "# Jalankan semuanya\n",
    "run_all(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4bf409-9a90-4e1c-8f7c-fb300b589981",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor\n",
    "Alasan Utama: Model berbasis kedekatan yang sangat fleksibel untuk data non-linier.\n",
    "\n",
    "Penjelasan: KNN bekerja dengan melihat data yang \"terdekat\" dengan contoh yang ingin diprediksi. Dalam konteks data medis, ini sangat berguna, karena pola dalam data mungkin tidak linier. Misalnya, dua pasien dengan tekanan darah yang sama mungkin memiliki hasil berbeda tergantung pada faktor-faktor lain seperti usia atau detak jantung.\n",
    "\n",
    "Kenapa Memilih Ini: KNN sangat cocok ketika hubungan antara fitur dan target tidak bisa dijelaskan secara linier. Jika model Logistic Regression gagal menangkap pola yang kompleks dalam data, KNN bisa memberikan alternatif yang lebih fleksibel dengan menggunakan kedekatan antar data untuk memprediksi hasil. Ini juga memberikan hasil yang baik tanpa perlu banyak tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c6b0c9-6476-4271-bbf0-7f5518d64b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "X = X_data.copy().to_numpy()\n",
    "y = y_data.copy().to_numpy()\n",
    "\n",
    "# Function untuk membuat pipeline model: Scaling sangat penting pada KNN karena berbasis jarak.\n",
    "def create_pipeline(n_neighbors=5, weights='uniform', metric='minkowski'):\n",
    "    return Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, metric=metric))\n",
    "    ])\n",
    "# weights: apakah semua tetangga bobotnya sama (uniform) atau dihitung berdasarkan jarak (distance).\n",
    "# metric: jenis metrik jarak, misalnya Euclidean atau Manhattan.\n",
    "\n",
    "# Parameter untuk RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'clf__n_neighbors': randint(1, 20),\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "# Parameter untuk GridSearchCV\n",
    "param_grid = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'clf__weights': ['uniform', 'distance'],\n",
    "    'clf__metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "def plot_multiple_confusion_matrices(conf_matrices, title):\n",
    "    n = len(conf_matrices)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(3.5 * n, 3.5))\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, (cm, name) in enumerate(conf_matrices):\n",
    "        ConfusionMatrixDisplay(confusion_matrix=cm).plot(ax=axes[i], cmap='Blues', colorbar=False)\n",
    "        axes[i].set_title(name)\n",
    "\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()  # Pastikan hanya panggil show sekali di sini\n",
    "    plt.close(fig)  # ⬅⬅⬅ Tambahkan ini untuk menghindari dobel\n",
    "\n",
    "\n",
    "# Fungsi evaluasi untuk KFold dan StratifiedKFold\n",
    "def evaluate_with_cv(cv_method, use_grid=False, use_random=False, show_conf_matrix=False):\n",
    "    default_scores = []\n",
    "    grid_scores = []\n",
    "    random_scores = []\n",
    "    fold_num = 1\n",
    "\n",
    "    # Untuk menyimpan semua confusion matrices\n",
    "    conf_matrices_default = []\n",
    "    conf_matrices_grid = []\n",
    "    conf_matrices_random = []\n",
    "\n",
    "    for train_idx, test_idx in cv_method.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Default\n",
    "        model = create_pipeline()\n",
    "        model.fit(X_train, y_train)\n",
    "        default_scores.append(model.score(X_test, y_test))\n",
    "\n",
    "        if show_conf_matrix:\n",
    "            y_pred = model.predict(X_test)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            conf_matrices_default.append((cm, f\"Default-Fold {fold_num}\"))\n",
    "\n",
    "        # GridSearchCV\n",
    "        if use_grid:\n",
    "            grid = GridSearchCV(create_pipeline(), param_grid, cv=3)\n",
    "            grid.fit(X_train, y_train)\n",
    "            grid_scores.append(grid.best_estimator_.score(X_test, y_test))\n",
    "            \n",
    "            if show_conf_matrix:\n",
    "                y_pred = grid.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_grid.append((cm, f\"GridSearch-Fold {fold_num}\"))\n",
    "\n",
    "        # RandomizedSearchCV\n",
    "        if use_random:\n",
    "            rand = RandomizedSearchCV(create_pipeline(), param_distributions=param_dist, n_iter=10, cv=3, random_state=42)\n",
    "            rand.fit(X_train, y_train)\n",
    "            random_scores.append(rand.best_estimator_.score(X_test, y_test))\n",
    "            \n",
    "            if show_conf_matrix:\n",
    "                y_pred = rand.best_estimator_.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                conf_matrices_random.append((cm, f\"RandomizedSearch-Fold {fold_num}\"))\n",
    "\n",
    "        fold_num += 1\n",
    "\n",
    "    # Tampilkan semua confusion matrix setelah loop\n",
    "    if show_conf_matrix:\n",
    "        plot_multiple_confusion_matrices(conf_matrices_default, \"Confusion Matrix - Default\")\n",
    "        if use_grid:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_grid, \"Confusion Matrix - GridSearchCV\")\n",
    "        if use_random:\n",
    "            plot_multiple_confusion_matrices(conf_matrices_random, \"Confusion Matrix - RandomizedSearchCV\")\n",
    "\n",
    "    return default_scores, grid_scores, random_scores\n",
    "\n",
    "# Fungsi plotting hasil\n",
    "def plot_fold_results(fold_scores_dict, title, labels):\n",
    "    folds = [f'Fold {i+1}' for i in range(len(next(iter(fold_scores_dict.values()))))]\n",
    "    y_pos = np.arange(len(folds))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    bar_height = 0.2\n",
    "    offsets = [-bar_height, 0, bar_height]\n",
    "    colors = ['gray', 'skyblue', 'lightgreen']\n",
    "    labels_legend = ['Default', 'GridSearchCV', 'RandomizedSearchCV']\n",
    "\n",
    "    for i, (label, scores) in enumerate(fold_scores_dict.items()):\n",
    "        plt.barh(y_pos + offsets[i], scores, height=bar_height, color=colors[i], label=labels_legend[i])\n",
    "        for j, score in enumerate(scores):\n",
    "            plt.text(score + 0.002, y_pos[j] + offsets[i], f\"{score:.4f}\", va='center', ha='left')\n",
    "\n",
    "    # Hitung mean dari masing-masing\n",
    "    mean_default = np.mean(kfold_default)\n",
    "    mean_grid = np.mean(kfold_grid)\n",
    "    mean_random = np.mean(kfold_random)\n",
    "\n",
    "    # Tambahkan titik/marker sebagai legend dan penanda mean\n",
    "    plt.scatter([mean_default]*len(kfold_default), range(len(kfold_default)),\n",
    "                marker='o', color='blue', label='Mean (Default)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_grid]*len(kfold_grid), range(len(kfold_grid)),\n",
    "                marker='x', color='navy', label='Mean (GridSearch)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_random]*len(kfold_random), range(len(kfold_random)),\n",
    "                marker='D', color='green', label='Mean (RandomSearch)', zorder=5)\n",
    "    plt.xlim(0.75, 1.0)\n",
    "\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Folds')\n",
    "    plt.yticks(y_pos, folds)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Evaluasi untuk KFold dan StratifiedKFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "plot_fold_results({\n",
    "    'Default': kfold_default,\n",
    "    'GridSearchCV': kfold_grid,\n",
    "    'RandomizedSearchCV': kfold_random\n",
    "}, 'KFold Cross-Validation Results', ['Default', 'GridSearchCV', 'RandomizedSearchCV'])\n",
    "kfold_default, kfold_grid, kfold_random = evaluate_with_cv(kfold, use_grid=True, use_random=True, show_conf_matrix=True)\n",
    "\n",
    "plot_fold_results({\n",
    "    'Default': strat_default,\n",
    "    'GridSearchCV': strat_grid,\n",
    "    'RandomizedSearchCV': strat_random\n",
    "}, 'StratifiedKFold Cross-Validation Results', ['Default', 'GridSearchCV', 'RandomizedSearchCV'])\n",
    "strat_default, strat_grid, strat_random = evaluate_with_cv(strat_kfold, use_grid=True, use_random=True, show_conf_matrix=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f0261-2ae6-42e7-b2b2-d5a0efe015fd",
   "metadata": {},
   "source": [
    "### Ensemble Learning memakai XGBoost dan Adaboost\n",
    "Alasan Utama: Menggabungkan kekuatan beberapa model untuk hasil yang lebih kuat dan stabil.\n",
    "\n",
    "Penjelasan: Model voting menggabungkan hasil dari berbagai model yang berbeda untuk menghasilkan prediksi akhir. Dalam kasus ini, kita menggabungkan:\n",
    "\n",
    "- XGBoost: Model boosting yang sangat kuat, dapat menangani data besar dan kompleks, serta cenderung memberikan hasil yang sangat baik dalam waktu yang efisien.\n",
    "\n",
    "- AdaBoost: Fokus pada memperbaiki kelemahan model sebelumnya dengan memberi bobot lebih pada data yang salah diklasifikasikan, meningkatkan akurasi secara bertahap.\n",
    "\n",
    "- KNN: Menambahkan pendekatan berbasis kedekatan yang memperkaya model dengan kemampuan mendeteksi pola lokal yang mungkin terlewatkan oleh model lain.\n",
    "\n",
    "Kenapa Memilih Ini: Dengan menggabungkan beberapa model berbeda, kita bisa memanfaatkan kelebihan masing-masing: XGBoost dan AdaBoost memberikan kekuatan dalam menangani kesalahan prediksi dan pola yang lebih kompleks, sementara KNN memperkenalkan elemen berbasis kedekatan. Ini memungkinkan model untuk bekerja lebih baik di berbagai kondisi dan mengurangi overfitting atau underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67960b-24d0-44c6-b086-5193e58ace30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Load dataset\n",
    "X = X_data.copy().to_numpy()\n",
    "y = y_data.copy().to_numpy()\n",
    "\n",
    "# Define parameter grids for GridSearchCV and RandomizedSearchCV\n",
    "param_xgb = {\n",
    "    # 'xgb__n_estimators': [50, 100, 150, 200],\n",
    "    # 'xgb__max_depth': [3, 5, 7, 10],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "param_ada = {\n",
    "    # 'ada__n_estimators': [50, 100, 150, 200],\n",
    "    'ada__learning_rate': [0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "param_xgb_random = {\n",
    "    # 'xgb__n_estimators': randint(50, 200),\n",
    "    # 'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.3)\n",
    "}\n",
    "param_ada_random = {\n",
    "    # 'ada__n_estimators': randint(50, 200),\n",
    "    'ada__learning_rate': uniform(0.01, 1.0)\n",
    "}\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def test_fold(cv_method, search_method, param_xgb, param_ada):\n",
    "    default_score = []\n",
    "    tuned_score = []\n",
    "    cm_default = []  # Menyimpan confusion matrix untuk default\n",
    "    cm_tuned = []    # Menyimpan confusion matrix untuk model tuning\n",
    "\n",
    "    for train_index, test_index in cv_method.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Default models\n",
    "        xgb = XGBClassifier()\n",
    "        ada = AdaBoostClassifier(algorithm='SAMME')\n",
    "        knn = KNeighborsClassifier()\n",
    "\n",
    "        # Default ensemble\n",
    "        ensemble_default = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('vote', VotingClassifier(estimators=[\n",
    "                ('xgb', xgb),\n",
    "                ('ada', ada),\n",
    "                ('knn', knn)\n",
    "            ], voting='soft'))\n",
    "        ])\n",
    "        ensemble_default.fit(X_train, y_train)\n",
    "        default_score.append(ensemble_default.score(X_test, y_test))\n",
    "\n",
    "        # Calculate confusion matrix for default\n",
    "        cm_default.append(confusion_matrix(y_test, ensemble_default.predict(X_test)))\n",
    "\n",
    "        # Hyperparameter tuning\n",
    "        xgb_pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('xgb', XGBClassifier())\n",
    "        ])\n",
    "        if search_method == 'grid':\n",
    "            xgb_search = GridSearchCV(xgb_pipe, param_grid=param_xgb, cv=3)\n",
    "        else:\n",
    "            xgb_search = RandomizedSearchCV(xgb_pipe, param_distributions=param_xgb_random, n_iter=10, cv=3, random_state=42)\n",
    "        \n",
    "        xgb_search.fit(X_train, y_train)\n",
    "\n",
    "        ada_pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ada', AdaBoostClassifier(algorithm='SAMME'))\n",
    "        ])\n",
    "        if search_method == 'grid':\n",
    "            ada_search = GridSearchCV(ada_pipe, param_grid=param_ada, cv=3)\n",
    "        else:\n",
    "            ada_search = RandomizedSearchCV(ada_pipe, param_distributions=param_ada_random, n_iter=10, cv=3, random_state=42)\n",
    "        \n",
    "        ada_search.fit(X_train, y_train)\n",
    "\n",
    "        # Tuned ensemble\n",
    "        ensemble_tuned = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('vote', VotingClassifier(estimators=[\n",
    "                ('xgb', xgb_search.best_estimator_.named_steps['xgb']),\n",
    "                ('ada', ada_search.best_estimator_.named_steps['ada']),\n",
    "                ('knn', knn)\n",
    "            ], voting='soft'))\n",
    "        ])\n",
    "        ensemble_tuned.fit(X_train, y_train)\n",
    "        tuned_score.append(ensemble_tuned.score(X_test, y_test))\n",
    "\n",
    "        # Calculate confusion matrix for tuned\n",
    "        cm_tuned.append(confusion_matrix(y_test, ensemble_tuned.predict(X_test)))\n",
    "\n",
    "    return default_score, tuned_score, cm_default, cm_tuned\n",
    "\n",
    "def plot_comparison(score_default, score_grid, score_random, cv_type, cm_default, cm_grid, cm_random):\n",
    "    folds = [f'Fold {i+1}' for i in range(len(score_default))]\n",
    "    x = np.arange(len(folds))\n",
    "    bar_width = 0.25\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for Default (no tuning)\n",
    "    plt.barh(x - bar_width, score_default, height=bar_width, label='Default (No Tuning)', color='gray')\n",
    "\n",
    "    # Plot for GridSearchCV\n",
    "    plt.barh(x, score_grid, height=bar_width, label='GridSearchCV Tuning', color='skyblue')\n",
    "\n",
    "    # Plot for RandomizedSearchCV\n",
    "    plt.barh(x + bar_width, score_random, height=bar_width, label='RandomizedSearchCV Tuning', color='lightgreen')\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        plt.text(score_default[i] + 0.001, x[i] - bar_width, f\"{score_default[i]:.4f}\", va='center')\n",
    "        plt.text(score_grid[i] + 0.001, x[i], f\"{score_grid[i]:.4f}\", va='center')\n",
    "        plt.text(score_random[i] + 0.001, x[i] + bar_width, f\"{score_random[i]:.4f}\", va='center')\n",
    "\n",
    "    # Hitung mean dari masing-masing\n",
    "    mean_default = np.mean(score_default)\n",
    "    mean_grid = np.mean(score_grid)\n",
    "    mean_random = np.mean(score_random)\n",
    "\n",
    "    # Tambahkan titik/marker sebagai legend dan penanda mean\n",
    "    plt.scatter([mean_default]*len(score_default), range(len(score_default)),\n",
    "                marker='o', color='blue', label='Mean (Default)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_grid]*len(score_grid), range(len(score_grid)),\n",
    "                marker='x', color='navy', label='Mean (GridSearch)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_random]*len(score_random), range(len(score_random)),\n",
    "                marker='D', color='green', label='Mean (RandomSearch)', zorder=5)\n",
    "    \n",
    "    plt.xlim(0.75, 1.0)\n",
    "    plt.yticks(x, folds)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title(f'Comparison of Voting Classifier Accuracies ({cv_type})')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Menampilkan Confusion Matrix untuk setiap metode\n",
    "    for method, cm in zip(['Default', 'GridSearchCV', 'RandomizedSearchCV'], [cm_default, cm_grid, cm_random]):\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))  # 1 baris, 5 kolom\n",
    "        fig.suptitle(f'Confusion Matrices - {method}', fontsize=16)\n",
    "\n",
    "        for i, cm_fold in enumerate(cm):\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm_fold)\n",
    "            disp.plot(cmap='Blues', values_format='d', ax=axes[i], colorbar=False)\n",
    "            axes[i].set_title(f'Fold {i+1}')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Supaya suptitle tidak kepotong\n",
    "        plt.show()\n",
    "\n",
    "# KFold + Default\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "score_default_kf, score_grid_kf, score_random_kf = [], [], []\n",
    "cm_default_kf, cm_grid_kf, cm_random_kf = [], [], []\n",
    "for method in ['none', 'grid', 'random']:\n",
    "    score_default, score_tuned, cm_default, cm_tuned = test_fold(kf, method, param_xgb, param_ada)\n",
    "    if method == 'none':\n",
    "        score_default_kf = score_default\n",
    "        cm_default_kf = cm_default\n",
    "    elif method == 'grid':\n",
    "        score_grid_kf = score_tuned\n",
    "        cm_grid_kf = cm_tuned\n",
    "    else:\n",
    "        score_random_kf = score_tuned\n",
    "        cm_random_kf = cm_tuned\n",
    "\n",
    "# StratifiedKFold + Default\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "score_default_skf, score_grid_skf, score_random_skf = [], [], []\n",
    "cm_default_skf, cm_grid_skf, cm_random_skf = [], [], []\n",
    "for method in ['none', 'grid', 'random']:\n",
    "    score_default, score_tuned, cm_default, cm_tuned = test_fold(skf, method, param_xgb, param_ada)\n",
    "    if method == 'none':\n",
    "        score_default_skf = score_default\n",
    "        cm_default_skf = cm_default\n",
    "    elif method == 'grid':\n",
    "        score_grid_skf = score_tuned\n",
    "        cm_grid_skf = cm_tuned\n",
    "    else:\n",
    "        score_random_skf = score_tuned\n",
    "        cm_random_skf = cm_tuned\n",
    "\n",
    "# Plot results for KFold\n",
    "plot_comparison(score_default_kf, score_grid_kf, score_random_kf, \"K-Fold\", cm_default_kf, cm_grid_kf, cm_random_kf)\n",
    "\n",
    "# Plot results for StratifiedKFold\n",
    "plot_comparison(score_default_skf, score_grid_skf, score_random_skf, \"Stratified K-Fold\", cm_default_skf, cm_grid_skf, cm_random_skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d2684-51ef-4780-995c-2d6990d4cdc1",
   "metadata": {},
   "source": [
    "#### Kesimpulan Visualisasi:\n",
    "\n",
    "Secara umum, Stratified K-Fold memberikan hasil yang sedikit lebih stabil dan konsisten antar fold dibandingkan dengan K-Fold biasa. Hal ini terlihat dari sebaran nilai akurasi yang cenderung lebih merata pada Stratified K-Fold, sedangkan pada K-Fold biasa terdapat variasi yang cukup signifikan antar fold (contoh: Fold 4 di K-Fold sering drop akurasinya secara drastis). Stratified K-Fold menjaga proporsi kelas target pada setiap fold, sementara K-Fold biasa tidak, sehingga rawan terjadi pembagian data yang tidak seimbang, apalagi pada dataset yang tidak seimbang (imbalanced class).\n",
    "\n",
    "Kesimpulan antar fold menunjukkan bahwa Fold 2 dan Fold 1 sering memberikan akurasi lebih tinggi dan stabil, terutama pada Stratified K-Fold. Sementara itu, Fold 4 dan 5 cenderung jadi fold yang paling menantang (dengan performa turun) pada K-Fold biasa. Berdasarkan keseluruhan grafik, metode dengan Stratified K-Fold + GridSearchCV atau RandomizedSearchCV umumnya memberikan kombinasi akurasi tertinggi dan paling stabil, sehingga dapat disimpulkan sebagai metode yang paling optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dca399-2a43-4244-b643-5e69fb6a5894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Load dataset\n",
    "X = X_data.copy().to_numpy()\n",
    "y = y_data.copy().to_numpy()\n",
    "\n",
    "# Define parameter grids for GridSearchCV and RandomizedSearchCV\n",
    "param_xgb = {\n",
    "    'xgb__n_estimators': [50, 100, 150, 200],\n",
    "    'xgb__max_depth': [3, 5, 7, 10],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "param_ada = {\n",
    "    'ada__n_estimators': [50, 100, 150, 200],\n",
    "    'ada__learning_rate': [0.01, 0.1, 0.5, 1.0]\n",
    "}\n",
    "param_xgb_random = {\n",
    "    'xgb__n_estimators': randint(50, 200),\n",
    "    'xgb__max_depth': randint(3, 10),\n",
    "    'xgb__learning_rate': uniform(0.01, 0.3)\n",
    "}\n",
    "param_ada_random = {\n",
    "    'ada__n_estimators': randint(50, 200),\n",
    "    'ada__learning_rate': uniform(0.01, 1.0)\n",
    "}\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def test_fold(cv_method, search_method, param_xgb, param_ada):\n",
    "    default_score = []\n",
    "    tuned_score = []\n",
    "    cm_default = []  # Menyimpan confusion matrix untuk default\n",
    "    cm_tuned = []    # Menyimpan confusion matrix untuk model tuning\n",
    "\n",
    "    for train_index, test_index in cv_method.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Default models\n",
    "        xgb = XGBClassifier()\n",
    "        ada = AdaBoostClassifier(algorithm='SAMME')\n",
    "        knn = KNeighborsClassifier()\n",
    "\n",
    "        # Default ensemble\n",
    "        ensemble_default = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('vote', VotingClassifier(estimators=[\n",
    "                ('xgb', xgb),\n",
    "                ('ada', ada),\n",
    "                ('knn', knn)\n",
    "            ], voting='soft'))\n",
    "        ])\n",
    "        ensemble_default.fit(X_train, y_train)\n",
    "        default_score.append(ensemble_default.score(X_test, y_test))\n",
    "\n",
    "        # Calculate confusion matrix for default\n",
    "        cm_default.append(confusion_matrix(y_test, ensemble_default.predict(X_test)))\n",
    "\n",
    "        # Hyperparameter tuning\n",
    "        xgb_pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('xgb', XGBClassifier())\n",
    "        ])\n",
    "        if search_method == 'grid':\n",
    "            xgb_search = GridSearchCV(xgb_pipe, param_grid=param_xgb, cv=3)\n",
    "        else:\n",
    "            xgb_search = RandomizedSearchCV(xgb_pipe, param_distributions=param_xgb_random, n_iter=10, cv=3, random_state=42)\n",
    "        \n",
    "        xgb_search.fit(X_train, y_train)\n",
    "\n",
    "        ada_pipe = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('ada', AdaBoostClassifier(algorithm='SAMME'))\n",
    "        ])\n",
    "        if search_method == 'grid':\n",
    "            ada_search = GridSearchCV(ada_pipe, param_grid=param_ada, cv=3)\n",
    "        else:\n",
    "            ada_search = RandomizedSearchCV(ada_pipe, param_distributions=param_ada_random, n_iter=10, cv=3, random_state=42)\n",
    "        \n",
    "        ada_search.fit(X_train, y_train)\n",
    "\n",
    "        # Tuned ensemble\n",
    "        ensemble_tuned = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('vote', VotingClassifier(estimators=[\n",
    "                ('xgb', xgb_search.best_estimator_.named_steps['xgb']),\n",
    "                ('ada', ada_search.best_estimator_.named_steps['ada']),\n",
    "                ('knn', knn)\n",
    "            ], voting='soft'))\n",
    "        ])\n",
    "        ensemble_tuned.fit(X_train, y_train)\n",
    "        tuned_score.append(ensemble_tuned.score(X_test, y_test))\n",
    "\n",
    "        # Calculate confusion matrix for tuned\n",
    "        cm_tuned.append(confusion_matrix(y_test, ensemble_tuned.predict(X_test)))\n",
    "\n",
    "    return default_score, tuned_score, cm_default, cm_tuned\n",
    "\n",
    "def plot_comparison(score_default, score_grid, score_random, cv_type, cm_default, cm_grid, cm_random):\n",
    "    folds = [f'Fold {i+1}' for i in range(len(score_default))]\n",
    "    x = np.arange(len(folds))\n",
    "    bar_width = 0.25\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot for Default (no tuning)\n",
    "    plt.barh(x - bar_width, score_default, height=bar_width, label='Default (No Tuning)', color='gray')\n",
    "\n",
    "    # Plot for GridSearchCV\n",
    "    plt.barh(x, score_grid, height=bar_width, label='GridSearchCV Tuning', color='skyblue')\n",
    "\n",
    "    # Plot for RandomizedSearchCV\n",
    "    plt.barh(x + bar_width, score_random, height=bar_width, label='RandomizedSearchCV Tuning', color='lightgreen')\n",
    "\n",
    "    for i in range(len(folds)):\n",
    "        plt.text(score_default[i] + 0.001, x[i] - bar_width, f\"{score_default[i]:.4f}\", va='center')\n",
    "        plt.text(score_grid[i] + 0.001, x[i], f\"{score_grid[i]:.4f}\", va='center')\n",
    "        plt.text(score_random[i] + 0.001, x[i] + bar_width, f\"{score_random[i]:.4f}\", va='center')\n",
    "\n",
    "    # Hitung mean dari masing-masing\n",
    "    mean_default = np.mean(score_default)\n",
    "    mean_grid = np.mean(score_grid)\n",
    "    mean_random = np.mean(score_random)\n",
    "\n",
    "    # Tambahkan titik/marker sebagai legend dan penanda mean\n",
    "    plt.scatter([mean_default]*len(score_default), range(len(score_default)),\n",
    "                marker='o', color='blue', label='Mean (Default)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_grid]*len(score_grid), range(len(score_grid)),\n",
    "                marker='x', color='navy', label='Mean (GridSearch)', zorder=5)\n",
    "\n",
    "    plt.scatter([mean_random]*len(score_random), range(len(score_random)),\n",
    "                marker='D', color='green', label='Mean (RandomSearch)', zorder=5)\n",
    "    \n",
    "    plt.xlim(0.75, 1.0)\n",
    "    plt.yticks(x, folds)\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.title(f'Comparison of Voting Classifier Accuracies ({cv_type})')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Menampilkan Confusion Matrix untuk setiap metode\n",
    "    for method, cm in zip(['Default', 'GridSearchCV', 'RandomizedSearchCV'], [cm_default, cm_grid, cm_random]):\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(20, 4))  # 1 baris, 5 kolom\n",
    "        fig.suptitle(f'Confusion Matrices - {method}', fontsize=16)\n",
    "\n",
    "        for i, cm_fold in enumerate(cm):\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm_fold)\n",
    "            disp.plot(cmap='Blues', values_format='d', ax=axes[i], colorbar=False)\n",
    "            axes[i].set_title(f'Fold {i+1}')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Supaya suptitle tidak kepotong\n",
    "        plt.show()\n",
    "\n",
    "# KFold + Default\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "score_default_kf, score_grid_kf, score_random_kf = [], [], []\n",
    "cm_default_kf, cm_grid_kf, cm_random_kf = [], [], []\n",
    "for method in ['none', 'grid', 'random']:\n",
    "    score_default, score_tuned, cm_default, cm_tuned = test_fold(kf, method, param_xgb, param_ada)\n",
    "    if method == 'none':\n",
    "        score_default_kf = score_default\n",
    "        cm_default_kf = cm_default\n",
    "    elif method == 'grid':\n",
    "        score_grid_kf = score_tuned\n",
    "        cm_grid_kf = cm_tuned\n",
    "    else:\n",
    "        score_random_kf = score_tuned\n",
    "        cm_random_kf = cm_tuned\n",
    "\n",
    "# StratifiedKFold + Default\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "score_default_skf, score_grid_skf, score_random_skf = [], [], []\n",
    "cm_default_skf, cm_grid_skf, cm_random_skf = [], [], []\n",
    "for method in ['none', 'grid', 'random']:\n",
    "    score_default, score_tuned, cm_default, cm_tuned = test_fold(skf, method, param_xgb, param_ada)\n",
    "    if method == 'none':\n",
    "        score_default_skf = score_default\n",
    "        cm_default_skf = cm_default\n",
    "    elif method == 'grid':\n",
    "        score_grid_skf = score_tuned\n",
    "        cm_grid_skf = cm_tuned\n",
    "    else:\n",
    "        score_random_skf = score_tuned\n",
    "        cm_random_skf = cm_tuned\n",
    "\n",
    "# Plot results for KFold\n",
    "plot_comparison(score_default_kf, score_grid_kf, score_random_kf, \"K-Fold\", cm_default_kf, cm_grid_kf, cm_random_kf)\n",
    "\n",
    "# Plot results for StratifiedKFold\n",
    "plot_comparison(score_default_skf, score_grid_skf, score_random_skf, \"Stratified K-Fold\", cm_default_skf, cm_grid_skf, cm_random_skf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
